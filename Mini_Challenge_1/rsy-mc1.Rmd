---
title: "RSY-MC1"
author: "Patrick, Ben"
output: 
  html_notebook:
    toc: True
    toc_float: True
---
# Mini-Challenge Beschreibung
# Daten und Libraries
```{r}
library(tidyverse)
library(recommenderlab)
```

## Daten einlesen
```{r}
data(MovieLense)
```

## Library Methoden zum Datensatz MovieLense
```{r}
methods(class = class(MovieLense))
```

## Kopfzeilen vom Datensatz ausgeben
```{r}
head(as(MovieLense, "data.frame"))
```

## Fusszeilen vom Datensatz ausgeben
```{r}
tail(as(MovieLense, "data.frame"))
```

## Info zum Datensatz
```{r}
summary(as(MovieLense, "data.frame"))
```

## Datenframe Variabel erstellen
```{r}
MovieLenseEDA <- as(MovieLense, "data.frame")
```

# 1 Explorative Datenanalyse
Aufgabe 1: Untersuche den vollständigen MovieLense Datensatz 
(d.h. vor Datenreduktion!) und beantworte folgende Fragen

## 1. Welches sind die am häufigsten geschauten Genres/Filme?

### 1.1 Welches sind die am haeufigsten geschauten Filme?
```{r}
MovieLenseEDA %>% 
  group_by(item) %>% 
  summarise(Anzahl = n()) %>%
  arrange(desc(Anzahl)) 
```

### 1.2 Welches sind die am haeufigsten geschauten Genre?
```{r}
# Full Join mit df_movies_rating und MovieLenseMeta
MovieLenseEDA_Joined <- full_join(MovieLenseEDA, MovieLenseMeta, 
          by = c("item" = "title")) %>% 
  select(-c("user", "item", "rating", "year", "url")) 

# Aufsummieren der Genre Spalten
(colSums(MovieLenseEDA_Joined)) %>% sort(decreasing = TRUE)

### 
# Muessen wir Genre Unknown entfernen?
```

## 2. Wie verteilen sich die Kundenratings gesamthaft und nach Genres?
```{r}
# DataFrame join
MovieLenseEDA_Joined <- full_join(MovieLenseEDA, MovieLenseMeta, 
          by = c("item" = "title"))
```

### 2.1 Verteilung der Kundenratings Gesamthaft
```{r}
MovieLenseEDA_Joined$rating <- as.factor(MovieLenseEDA_Joined$rating)

MovieLenseEDA_Joined %>% group_by(rating) %>%
  summarize(Anzahl = n()) %>% 
  ggplot(aes(x = rating, y = Anzahl)) + 
  geom_bar(stat = "identity", 
           fill = "lightblue", 
           color = "black") + 
  labs(x = "Ratings", 
       y = "Anzahl", 
       title = "Kundenratings Gesamthaft",
       subtitle = "MovieLenseData")
```

### 2.2 Verteilung der Kundenratings nach Genre
```{r}
MovieLenseEDA_Joined$rating <- as.integer(MovieLenseEDA_Joined$rating)

MovieLenseEDA_Joined %>% 
  select(-c("item", "user", "year", "url")) %>% 
  pivot_longer(cols=c("unknown", "Action", "Adventure", "Animation", "Children's",
                      "Comedy", "Crime", "Documentary", "Drama", "Fantasy",
                      "Film-Noir", "Horror", "Musical", "Mystery", "Horror",
                      "Musical", "Mystery", "Romance", "Sci-Fi", "Thriller",
                      "War", "Western"),
               names_to = "Genre", values_to = "is_genre") %>%
  filter(is_genre == 1) %>% 
  ggplot(aes(x = rating)) +
  geom_bar(fill = "lightblue", color = "black") +
  labs(x = "Ratings", 
       y = "Anzahl", 
       title = "Verteilung der Kundenratings nach Genre",
       subtitle = "MovieLenseData") + 
  facet_wrap(~Genre)
```

## 3. Wie verteilen sich die mittleren Kundenratings pro Film?
```{r}
MovieLenseEDA %>% 
  group_by(item) %>% 
  summarize(mean_rating_per_film = mean(rating)) %>% 
  ggplot(aes(x = mean_rating_per_film)) + 
  geom_histogram(color = "black", fill = "lightblue", binwidth = 0.5) +
    labs(x = "Ratings", 
       y = "Anzahl", 
       title = "Verteilung der Mittlere Kundenratings",
       subtitle = "MovieLenseData")
```

## 4. Wie stark streuen die Ratings von individuellen Kunden?
```{r}
MovieLenseEDA %>% filter(user == c(1:9)) %>% 
  ggplot(aes(x = user, y = rating)) +
  geom_violin(color = "black", fill = "lightblue") +
  labs(x = "User", 
       y = "Ratings", 
       title = "Streueung der Ratings von individuellen Kunden (1-9)",
       subtitle = "MovieLenseData")
```

## 5. Welchen Einfluss hat die Normierung der Ratings pro Kunde auf deren Verteilung?
```{r}
MovieLensenormalized <- normalize(MovieLense)
MovieLenseEDA_Normalized <- (as(MovieLensenormalized, "data.frame"))

MovieLenseEDA_Normalized %>% filter(user == c(1:9)) %>% 
  ggplot(aes(x = user, y = rating)) +
  geom_violin(color = "black", fill = "lightblue") +
  labs(x = "User", 
       y = "Normalisierte Ratings", 
       title = "Normalisierte Streueung der Ratings von individuellen Kunden (1-9)",
       subtitle = "MovieLenseData")
```

```{r}
MovieLense
```

## 6. Welche strukturellen Charakteristika (z.B. Sparsity) und Auffälligkeiten zeigt die User-Item Matrix?
```{r}
image(x = MovieLense, 
      xlab = "Items", 
      ylab = "Users", 
      main = "Sparisty 943 x 1664 User-Item Matrix 943 x 1664") 

image(MovieLense[1:50,1:50],
      xlab = "Items",
      ylab = "Users", 
      main = "Sparisty 50 x 50 User-Item Matrix")

# nratings(MovieLense) zaehlt die Anzahl vorhandenen Kombinationen von User und Items
(nratings(MovieLense) / (dim(MovieLense)[1] * dim(MovieLense)[2]) * 100)
```
Jede Zeile von MovieLense entspricht einem Benutzer und jede Spalte einem Film. Gesamthaft gibt es 943 x 1664 = 1’569’152 Kombinationen zwischen User und Film. Allerdings hat nicht jeder Nutzer jeden Film gesehen, aus diesem Grund ist es wichtig die Sparisy Matrix zu betrachten. In MovieLense Matrix fehlen ca. 94% der Kombinationen. Ca. 6 % ist die Sparse Matrix gefuellt mit Werten. 

# 2 Datenreduktion
Aufgabe 2: Reduziere den MovieLense Datensatz auf rund 400 Kunden und 700 Filme, indem du Filme und Kunden mit sehr wenigen Ratings entfernst.

## 2.1 Vorbereitung
### 2.1.1 DataFrame neu einlesen
```{r}
MovieLenseToCut <- as(MovieLense, "data.frame")
```

```{r}
MovieLenseToCut
```

### 2.1.2 Auswahl der 400 Kunden
```{r}
MovieLense400User <- MovieLenseToCut %>% 
  group_by(user) %>% 
  summarize(Anzahl = n()) %>% 
  arrange(desc(Anzahl)) %>% 
  slice(0:400)
head(MovieLense400User)
```

### 2.1.3 Auswahl der 700 Movies
```{r}
MovieLense700Items <- MovieLenseToCut %>% 
  group_by(item) %>% 
  summarise(Anzahl = n()) %>% 
  arrange(desc(Anzahl)) %>% 
  slice(0:700)
head(MovieLense700Items)
```

### 2.1.4 DataFrame schneiden
```{r}
MovieLenseCut <- MovieLenseToCut %>% 
  filter(user %in% c(MovieLense400User$user))

MovieLenseCut <- MovieLenseCut %>% 
  filter(item %in% c(MovieLense700Items$item))

MovieLenseCut
```

Untersuche und dokumentiere die Eigenschaften des reduzierten Datensatzes und beschreibe den Effekt der Datenreduktion, d.h.

## 2.2 Anzahl Filme und Kunden sowie Sparsity vor und nach Datenreduktion,

### 2.2.1 Vor der Datenreduktion
```{r}
image(MovieLense)
```

```{r}
nratings(MovieLense) / (dim(MovieLense)[1] * dim(MovieLense)[2]) * 100
```

### 2.2.2 Nach Datenreduktion
```{r}
MovieLenseCompact <- as(MovieLenseCut, "realRatingMatrix")
image(MovieLenseCompact)
```

### 2.2.3Vergleich der Sparsity
```{r}
nratings(MovieLenseCompact) / (dim(MovieLenseCompact)[1] * dim(MovieLenseCompact)[2]) * 100
```
Durch die Datenreduktion hat nun die Sparsity Matrix eine Dimension von 400 x 700, sprich sind
280’000 Ratingfelder vorhanden. Davon sind nur ca. 24% mit tatsächlichen Ratings versehen. Dies macht verglichen zu den Ursprünglichen Sparsity Matrix eine Steigerung von 18% aus. Jedoch muss man bedenken, dass die Ursprüngliche Sparsity Matrix eine Dimension von 943 x 1664 hatte, sprich Gesamthaft 1’569’152 Ratingfelder. Beziehen wir uns nur auf die Ratingfelder, so haben wir den Datensatz um 1 - (280’000 / 1’569’152) * 100 ≈ 82% reduziert.  

## 2.3 Mittlere Kundenratings pro Film vor und nach Datenreduktion,
```{r}
MovieLenseCut %>% 
  group_by(item) %>% 
  summarize(mean_rating_per_film = mean(rating)) %>% 
  ggplot(aes(x = mean_rating_per_film)) + 
  geom_histogram(color = "black", fill = "lightblue", binwidth = 0.5) +
    labs(x = "Ratings", 
       y = "Anzahl", 
       title = "Mittlere Kundenratings Verteilung",
       subtitle = "MovieLenseData")
```

## 2.4 Für Gruppen: Quantifiziere “Intersection over Union” der Ratings der unterschiedlich reduzierten Datensätze.
```{r}
#MovieLenseCut - UrsprungsdataFrame
#MovieLenseToCut - Geschnittener DataFrame

# Intersection over Union in Prozent fuer den erstn Datensatz
nratings(MovieLenseCompact) / nratings(MovieLense) * 100

```

67.8% überschneidungen gibt es mit der gefilterten User-Item Matrix zur Ursprünglich, dass ist ein hoher Wert, aber bedankt man, dass wir die User und Filme nach den meisten Ratings gefiltert haben. 

# 3 Analyse Ähnlichkeitsmatrix
Aufgabe 3: Erzeuge einen IBCF Recommender und analysiere die Ähnlichkeitsmatrix des trainierten Modelles für den reduzierten Datensatz.

## 3.1 Zerlege den reduzierten MovieLense Datensatz in ein disjunktes Trainings-und Testdatenset im Verhältnis 4:1,
```{r}
training <- MovieLenseCompact[1:320] 
test <- MovieLenseCompact[321:400]

training
test
```

## 3.2 Trainiere ein IBCF Modell mit 30 Nachbarn und Cosine Similarity
```{r}
ribcf <- Recommender(training, "IBCF", param=list(k= 30, method = "cosine"))
ribcf
```

## 3.3 Bestimme die Verteilung der Filme, welche bei IBCF für paarweise Ähnlichkeitsvergleiche verwendet werden
```{r}
# get model
ribcf_model <- getModel(ribcf)

# create DataFrame 
ribcf_sim_df <- as.data.frame(colSums(ribcf_model$sim > 0))

# Item als neue Spalte hinzufuegen und Index entfernen
ribcf_sim_df_ <- cbind(item = rownames(ribcf_sim_df), ribcf_sim_df)
rownames(ribcf_sim_df_) <- NULL

# Visualiseren mittels Histogramm
ribcf_sim_df_ %>%
  rename(Anzahl = 2) %>% 
  ggplot(aes(x = Anzahl)) + 
  geom_histogram(binwidth =  0.1) +
  labs(title = "Verteilung der Ähnlichkeitsvergleiche",
       x = "Anzahl Filme als Nachbar", 
       y = "Anzahl")
```
Im Histogramm erkennt man die Anzahl Filme die als Nachbar bei einem anderen Film 
auftauchen.  

## 3.4 Bestimme die Filme, die am häufigsten in der Cosine-Ähnlichkeitsmatrix auftauchen und analysiere deren Vorkommen und Ratings im reduzierten Datensatz.
```{r}
ribcf_sim_df_
```

```{r}
ribcf_sim_df_ %>% 
  rename(Anzahl = 2) %>% 
  arrange(desc(Anzahl)) %>% 
  top_n(10) %>% 
  ggplot(aes(x = Anzahl, y = item)) +
  geom_col(alpha = 0.5, color = "black", fill = "limegreen")
  
```

Top 10 Filme die am haeufigesten in der Nachbarschaft andere Filme auftauchen.

# 4 Implementierung Ähnlichkeitsmatrix
Aufgabe 4 (DIY): Implementiere eine Funktion zur effizienten
Berechnung von sparsen Ähnlichkeitsmatrizen für IBCF RS und
analysiere die Resultate für 100 zufällig gewählte Filme.

## 4.1 Implementiere eine Funktion, um (a) für ordinale Ratings effizient
die Cosine Similarity und (b) für binäre Ratings effizient die Jaccard
Similarity zu berechnen,
```{r}
number_user <- 100
number_item <- 100
```

### 4.1.1 Cosine Similarity 
```{r}
get_cossim_4 <- function(RatingMatrix, n_user, n_item){
 
  sliced_matrix <- getRatingMatrix(RatingMatrix[1:n_user, 1:n_item])
  
  sliced_matrix_t <- t(sliced_matrix)
  
  temp_sim <- sliced_matrix_t / sqrt(rowSums(sliced_matrix_t ** 2))

  cossim_matrix <- temp_sim %*% t(temp_sim)

  cossim_matrix
}
```

```{r}
result_cossim_4 <- get_cossim_4(MovieLense, number_user, number_item)
result_cossim_4[1:5,1:5]
```

### 4.1.2 Jaccard Similarity
```{r}
get_jaccardsim_4 <- function(RatingMatrix, n_user, n_item){
  
  sliced_matrix_bin <- as(binarize(RatingMatrix[1:n_user, 1:n_item], minRating=4), "matrix")
  
  sliced_matrix_bin_t <- t(sliced_matrix_bin)
  
  matrix_corssprod <- tcrossprod(sliced_matrix_bin_t)
  
  im <- which(matrix_corssprod > 0, arr.ind=TRUE)
  b <- rowSums(sliced_matrix_bin_t)
  Aim <- matrix_corssprod[im]
  
  J = sparseMatrix(
            i = im[,1],
            j = im[,2],
            x = Aim / (b[im[,1]] + b[im[,2]] - Aim),
            dims = dim(matrix_corssprod)
      )
  
  J <- data.matrix(J)
  
  J
}

```

```{r}
get_jaccardsim_4(MovieLense, number_user, number_item)
```

## 4.2 Vergleiche deine Implementierung der Cosine-basierten
Ähnlichkeitsmatrix für ordinale Ratings mit der via recommenderlab
und einem anderen R-Paket erzeugten Ähnlichkeitsmatrix,
```{r}

```

### 4.2.1 Vergleich Cosine Similiarty mit Recommenderlab
```{r}
recom_simcosin_4 <- as.matrix(similarity(normalize(MovieLense[1:number_user, 1:number_item]), which = "items", method = "cosine"))

recom_simcosin_4[1:4,1:4]
```

```{r}
result_cossim_4_scaled <- 1 / 2 * (result_cossim_4 + 1)

result_cossim_4_scaled[1:4,1:4]
```

### 4.2.2 Vergleich Cosine Similiarity mit anderem R-Paket
```{r}
library(lsa)

rec_simMat <- similarity(MovieLenseCompact[,1:3], which = "items")
rec_simMat

# simMat_lsa <- cosine(DfforSimMatrix, y = NULL)
```

## 4.3 Vergleiche deine mittels Cosine Similarity erzeugten Ähnlichkeitsmatrix für ordinale Ratings mit der Jaccard-basierten
Ähnlichkeitsmatrix für binäre Ratings.
```{r}

```


# 5 Analyse Top-N Listen - IBCF vs UBCF
Aufgabe 5: Vergleiche und diskutiere Top-N Empfehlungen von IBCF
und UBCF Modellen mit 30 Nachbarn und Cosine Similarity für den
reduzierten Datensatz.
## 5.1 Berechne Top-15 Empfehlungen für Testkunden mit IBCF und UBCF 
### 5.1.1 ribcf & rubcf Modell trainieren
```{r}
ribcf <- Recommender(training, "IBCF", param=list(k= 30, method = "cosine"))
ribcf
rubcf <- Recommender(training, "UBCF", param=list(nn= 30, method = "cosine"))
rubcf
```

### 5.1.2 Model Predicitions erstellen
```{r}
ribcftopNList <- predict(ribcf, test, n=15)
ribcftopNList

rubcftopNList <- predict(rubcf, test, n=15)
rubcftopNList
```

```{r}
as(ribcftopNList, "list")
```

## 5.2 Vergleiche die Top-15 Empfehlungen und deren Verteilung und
diskutiere Gemeinsamkeiten und Unterschiede zwischen IBCF und
UBCF für alle Testkunden.
```{r}
cftopNList_to_df <- function(cftopNList, namedf){
  temp <- as(cftopNList, "list") %>% combine() %>% data.frame()
  colnames(temp)[1]  <- namedf
  temp <- temp %>%
    group_by_at(1) %>%
    summarise(Anzahl = n()) %>%
    arrange(desc(Anzahl))
  temp
}
```

```{r}
ribcftopNList <- cftopNList_to_df(ribcftopNList, "ribcftopNList")
ribcftopNList

rubcftopNList <- cftopNList_to_df(rubcftopNList, "rubcftopNList")
rubcftopNList
```

### 5.2.1 Verteilungen visualisieren
```{r}
ribcftopNList %>% 
  ggplot(aes(x = Anzahl)) + 
  geom_histogram(fill = "lightblue", color = "black") +
  labs(title = "Verteilung der Anzahl Empfehlungen ribcf")
```

```{r}
rubcftopNList %>% 
  ggplot(aes(x = Anzahl)) + 
  geom_histogram(fill = "lightblue", color = "black") +
  labs(title = "Verteilung der Anzahl Empfehlungen rubcf")
```

Die erwähnte Behauptung “Recommender Systeme machen für alle Nutzer die gleichen Empfehlungen” kann dank dieser Histogramme verworfen werden. Sehr viele Filme werden nur wenigen User (<4) empfohlen.
Weiterer Text folgt.


# 6 Analyse Top-N Listen - Ratings
Aufgabe 6: Untersuche den Einfluss von Ratings (ordinale vs binäre Ratings) und Modelltyp (IBCF vs UBCF) auf Top-N Empfehlungen für den reduzierten Datensatz. Vergleiche den Anteil übereinstimmender Empfehlungen der Top-15 Liste für
## 6.1 IBCF vs UBCF, beide mit ordinalem Rating und Cosine Similarity für alle Testkunden,
```{r}
paste("Anzahl IBCF:", nrow(ribcftopNList))
paste("Anzahl UBCF:", nrow(rubcftopNList))

IntersectordRatCosine <- intersect(ribcftopNList$ribcftopNList, rubcftopNList$rubcftopNList)

paste("Anzahl gemeinsame Empfehlungen:", length(IntersectordRatCosine))
paste("Anteil IBCF:", length(IntersectordRatCosine) / nrow(ribcftopNList) * 100)
paste("Anteil UBCF:", length(IntersectordRatCosine) / nrow(rubcftopNList) * 100)
```

## 6.2 IBCF vs UBCF, beide mit binärem Rating und Jaccard Similarity für alle Testkunden,
```{r}
training_bin <- binarize(training, minRating = 4)
test_bin <- binarize(test, minRating = 4)

ribcf_bin <- Recommender(training_bin, "IBCF", param=list(k= 30, method = "jaccard"))

ribcf_bin

rubcf_bin <- Recommender(training_bin, "UBCF", param=list(nn= 30, method = "jaccard"))
rubcf_bin
```

```{r}
ribcftopNList_bin = predict(ribcf_bin, test_bin, n=15)
ribcftopNList_bin

rubcftopNList_bin = predict(rubcf_bin, test_bin, n=15)
rubcftopNList_bin
```

```{r}
ribcftopNList_bin <- cftopNList_to_df(ribcftopNList_bin, "ribcftopNList_bin")
ribcftopNList_bin

rubcftopNList_bin <- cftopNList_to_df(rubcftopNList_bin, "rubcftopNList_bin")
rubcftopNList_bin
```

```{r}
paste("Anzahl IBCF binär:", nrow(ribcftopNList_bin))
paste("Anzahl UBCF binär:", nrow(rubcftopNList_bin))

IntersectbinRatJaccard <- intersect(ribcftopNList_bin$ribcftopNList_bin, rubcftopNList_bin$rubcftopNList_bin)

paste("Anzahl gemeinsame Empfehlungen binär:", length(IntersectbinRatJaccard))
paste("Anteil IBCF binär:", length(IntersectbinRatJaccard) / nrow(ribcftopNList_bin) * 100)
paste("Anteil UBCF binär:", length(IntersectbinRatJaccard) / nrow(rubcftopNList_bin) * 100)
```
Zu diskutieren: Wieso sind die Anzahl Übereinstimmungen am höchsten sind, wenn minRating 5 ist.

## 6.3 UBCF mit ordinalem (Cosine Similarity) vs UBCF mit binärem Rating (Jaccard Similarity) für alle Testkunden.
```{r}
paste("Anzahl UBCF:", nrow(rubcftopNList))
paste("Anzahl UBCF binär:", nrow(rubcftopNList_bin))

Intersectmixed <- intersect(rubcftopNList$rubcftopNList, rubcftopNList_bin$rubcftopNList_bin)

paste("Anzahl gemeinsame Empfehlungen gemischt:", length(Intersectmixed))
paste("Anzahl UBCF:", length(Intersectmixed) / nrow(rubcftopNList) * 100)
paste("Anteil UBCF binär:", length(Intersectmixed) / nrow(rubcftopNList_bin) * 100)
```

```{r}
#Histogramm der Vergleiche
```

# 7 Analyse Top-N Listen - IBCF vs SVD
Aufgabe 7: Vergleiche
Memory-based IBCF und Modell-based SVD Recommenders bezüglich Überschneidung ihrer Top-N Empfehlungen für die User-Item Matrix des reduzierten Datensatzes (Basis: reduzierter Datensatz, IBCF mit 30 Nachbarn und Cosine Similarity).
Vergleiche wie sich der Anteil übereinstimmender Empfehlungen der Top-15 Liste für IBCF vs verschiedene SVD Modelle verändert, wenn die Anzahl der Singulärwerte für SVD von 10 auf 20, 30, 40, 50 verändert wird.
```{r}
generate_SVD_topNList<- function(ksvd){
	temp <- Recommender(training, "SVD", param=list(k= ksvd))
	temp <- predict(temp, test, n=15)
  temp
}
```

```{r}
rsvd10topNList <- generate_SVD_topNList(10)
rsvd20topNList <- generate_SVD_topNList(20)
rsvd30topNList <- generate_SVD_topNList(30)
rsvd40topNList <- generate_SVD_topNList(40)
rsvd50topNList <- generate_SVD_topNList(50)
```

```{r}
rsvd10topNList <- cftopNList_to_df(rsvd10topNList, "rsvd10topNList")
rsvd20topNList <- cftopNList_to_df(rsvd20topNList, "rsvd20topNList")
rsvd30topNList <- cftopNList_to_df(rsvd30topNList, "rsvd30topNList")
rsvd40topNList <- cftopNList_to_df(rsvd40topNList, "rsvd40topNList")
rsvd50topNList <- cftopNList_to_df(rsvd50topNList, "rsvd50topNList")
```

```{r}
IntersectIBCFSVD10 <- intersect(ribcftopNList$ribcftopNList, rsvd10topNList$rsvd10topNList)
paste("Anzahl gemeinsame Empfehlungen SVD10:", length(IntersectIBCFSVD10))
paste("Anteil SVD10:", length(IntersectIBCFSVD10) / nrow(rsvd10topNList) * 100)

IntersectIBCFSVD20 <- intersect(ribcftopNList$ribcftopNList, rsvd20topNList$rsvd20topNList)
paste("Anzahl gemeinsame Empfehlungen SVD20:", length(IntersectIBCFSVD20))
paste("Anteil SVD20:", length(IntersectIBCFSVD20) / nrow(rsvd20topNList) * 100)

IntersectIBCFSVD30 <- intersect(ribcftopNList$ribcftopNList, rsvd30topNList$rsvd30topNList)
paste("Anzahl gemeinsame Empfehlungen SVD30:", length(IntersectIBCFSVD30))
paste("Anteil SVD30:", length(IntersectIBCFSVD30) / nrow(rsvd30topNList) * 100)

IntersectIBCFSVD40 <- intersect(ribcftopNList$ribcftopNList, rsvd40topNList$rsvd40topNList)
paste("Anzahl gemeinsame Empfehlungen SVD40:", length(IntersectIBCFSVD40))
paste("Anteil SVD40:", length(IntersectIBCFSVD40) / nrow(rsvd40topNList) * 100)

IntersectIBCFSVD50 <- intersect(ribcftopNList$ribcftopNList, rsvd50topNList$rsvd50topNList)
paste("Anzahl gemeinsame Empfehlungen SVD50:", length(IntersectIBCFSVD50))
paste("Anteil SVD50:", length(IntersectIBCFSVD50) / nrow(rsvd50topNList) * 100)
```

# 8 Implementierung Top-N Metriken
Aufgabe 8 (DIY) 
## 8.1 CoverageN 
```{r}
ribcf_8 <- Recommender(MovieLense, "IBCF", param=list(k= 30, method = "cosine"))
ribcf_8

ribcftopNList_8 <- predict(ribcf_8, MovieLense, n=15)
ribcftopNList_8

list_items_8 <- unique(unlist(as(ribcftopNList_8, "list"), use.names = FALSE))
len_items_8 <- length(list_items_8)

len_all_items_8 <- dim(MovieLense)[2]
len_all_items_8

coverageN <- len_items_8 / len_all_items_8
coverageN
```
41.7 % der vorhandenen Filme werden empfohlen.

## 8.2 NoveltyN
```{r}
nratings(MovieLense) / len_all_items_8
```

# 9 Wahl des optimalen Recommenders
Aufgabe 9
## 9.1 Verwende für die Evaluierung 10-fache Kreuzvalidierung
```{r}
set.seed(1234)
scheme <- evaluationScheme(MovieLenseCompact, method="cross-validation", k = 10, given=3, goodRating=5)
scheme
```

## 9.2 Begründe deine Wahl von Metriken und Modell
```{r}
algorithms <- list("hybrid" = list(name = "HYBRID", param =list(recommenders = list(SVD = list(name="SVD", param=list(k = 40)),
                                                                                    POPULAR = list(name = "POPULAR", param = NULL)
                                                                                    ))),
                   "libmf" = list(name="LIBMF", param=list(dim=10)),
                   "popular items" = list(name="POPULAR", param=NULL),
                   "user-based CF" = list(name="UBCF", param=list(nn=50)),
                   "item-based CF" = list(name="IBCF", param=list(k=50)),
                   "SVD40" = list(name="SVD", param=list(k = 40)))
results <- evaluate(scheme, algorithms, type = "topNList", n=c(10, 15, 20, 25, 30))
```

```{r}
plot(results, annotate=c(1,3), legend="topleft")
```

## 9.3 Analysiere das beste Modell für Top-N Recommendations mit N = 10, 15, 20, 25 und 30,
vieles blabaalabaaassss

## 9.4 Optimiere dein bestes Modell hinsichtlich Hyperparametern
```{r}
algorithmsimprovedrecom <- list("popular items center" = list(name="POPULAR", param=NULL),
                   "popular items Z-score" = list(name="POPULAR", param=list(normalize="Z-score")))
resultsimprovedrecom <- evaluate(scheme, algorithmsimprovedrecom, type = "topNList", n=c(10, 15, 20, 25, 30))
```

```{r}
plot(resultsimprovedrecom, annotate=c(1,3), legend="topleft")
```

Hinweis: Verwende für den Top-Movie Recommender die Filme mit den höchsten Durchschnittsratings.
# 10 Implementierung Top-N Monitor
Aufgabe 10 (DIY): Untersuche die relative Übereinstimmung zwischen
Top-N Empfehlungen und präferierten Filmen für 4 unterschiedliche
Modelle (z.B. IBCF und UBCF mit unterschiedlichen Ähnlichkeitsmetriken / Nachbarschaften sowie SVD mit unterschiedlicher
Dimensionalitätsreduktion).

## 10.1 Fixiere 20 zufällig gewählte Testkunden für alle Modellvergleiche,
```{r}
# select 20 random users
set.seed(1234)
testUsers <- sample(1:nrow(MovieLense), 20)
testUsers

# filter MovieLense by testUsers
MovieLenseTest <- MovieLense[testUsers,] 
MovieLenseTest
```

## 10.2 Bestimme den Anteil der Top-N Empfehlung nach Genres pro Kunde,
```{r}
# get from every TestUsers the Top_N item list
ribcf_10 <- Recommender(MovieLenseTest, "IBCF", param=list(k= 30, method = "cosine"))

# predict Top-N items for every user
ribcftopNList_10 <- predict(ribcf_10, MovieLenseTest, n=15)

# create a list with the topN items for every user
ribcftopNList_10_list <- as(ribcftopNList_10, "list")

# create a tibble with the topN items for every user
ribcftopNList_10_tibble <- as_tibble(ribcftopNList_10_list)

# transform the tibble to a data frame
ribcftopNList_10_df <- as.data.frame(ribcftopNList_10_tibble)

# replace colname with testUsers
colnames(ribcftopNList_10_df) <- testUsers

# transpose data frame
ribcftopNList_10_df_transposed <- t(ribcftopNList_10_df)

# change ribcftopNList_10_df_transposed to a tibble
ribcftopNList_10_df_transposed_tibble <- as_tibble(ribcftopNList_10_df_transposed)

# add a column with the testUsers
ribcftopNList_10_df_transposed_tibble$testUsers <- testUsers

# pivot longer dataframe
ribcftopNList_10_df_transposed_tibble_pivot <- pivot_longer(ribcftopNList_10_df_transposed_tibble, cols = 1:15, names_to = "topN", values_to = "itemID")

# get genre from each item
ribcftopNList_10_df_transposed_tibble_pivot_genre <- left_join(ribcftopNList_10_df_transposed_tibble_pivot, MovieLenseMeta, by = c("itemID" = "title"))
ribcftopNList_10_df_transposed_tibble_pivot_genre

# drop columns topN, year, url
ribcftopNList_10_df_transposed_tibble_pivot_genre <- select(ribcftopNList_10_df_transposed_tibble_pivot_genre, -topN, -year, -url, -itemID)
ribcftopNList_10_df_transposed_tibble_pivot_genre
```

```{r}
# pivot longer dataframe
ribcftopNList_10_df_transposed_tibble_pivot_genre %>% group_by(testUsers) %>%
  summarise(across(everything(), ~ sum(., is.na(.), 0)))
```



## 10.3 Bestimme pro Kunde den Anteil nach Genres seiner Top-Filme
(=Filme mit besten Bewertungen),
```{r}

```

## 10.4 Vergleiche pro Kunde Top-Empfehlungen vs Top-Filme nach Genres,
```{r}

```

## 10.5 Definiere eine Qualitätsmetrik für Top-N Listen und teste sie.
```{r}

```

