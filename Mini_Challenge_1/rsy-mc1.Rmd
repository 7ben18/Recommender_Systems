---
title: "RSY-MC1"
author: "Patrick Schürmann, Si Ben Tran"
output: 
  html_notebook:
    toc: True
    toc_float: True
---
# Mini-Challenge Beschreibung
# Daten und Libraries
```{r}
library(tidyverse)
library(recommenderlab)
```

# Daten einlesen
```{r}
data(MovieLense)
```

# Library Methoden zum Datensatz MovieLense
```{r}
methods(class = class(MovieLense))
```
# MovieLense Dataframe erstellen
```{r}
MovieLenseEDA <- as(MovieLense, "data.frame")
```


# Kopfzeile und Fusszeile vom Datensatz ausgeben
```{r}
head(MovieLenseEDA)

tail(MovieLenseEDA)
```

# Infos zum Datensatz
```{r}
summary(MovieLenseEDA)
```

# 1 Explorative Datenanalyse
Aufgabe 1: Untersuche den vollständigen MovieLense Datensatz 
(d.h. vor Datenreduktion!) und beantworte folgende Fragen:

## 1.1 Welches sind die am häufigsten geschauten Genres/Filme?

### 1.1.1 Welches sind die am häufigsten geschauten Filme?
```{r}
MovieLenseEDA %>% 
  group_by(item) %>% 
  summarise(Anzahl = n()) %>%
  arrange(desc(Anzahl)) %>% 
  head(n=10)
```
In der Tabelle oben ersichtlich, die Top-10 meisten geschauten Filme. Die Spalte "Anzahl" zeigt mir die, wie häufig ein Film angeschaut wurde. 

### 1.1.2 Welches sind die am häufigsten geschauten Genre?
```{r}
# Full Join mit df_movies_rating und MovieLenseMeta
MovieLenseEDA_Joined <- full_join(MovieLenseEDA, MovieLenseMeta, 
          by = c("item" = "title")) %>% 
  select(-c("user", "item", "rating", "year", "url")) 

# Aufsummieren der Genre Spalten
(colSums(MovieLenseEDA_Joined)) %>% sort(decreasing = TRUE)

```
Wir erkennen, dass die am häufigsten geschauten Genre "Drama" ist. Auf dem zweiten Platz befindet sich "Comdey" und auf dem dritten "Action" Filme. 


## 1.2 Wie verteilen sich die Kundenratings gesamthaft und nach Genres?
```{r}
# DataFrame join
MovieLenseEDA_Joined <- full_join(MovieLenseEDA, MovieLenseMeta, 
          by = c("item" = "title"))
```

### 1.2.1 Verteilung der Kundenratings Gesamthaft
```{r}
MovieLenseEDA_Joined$rating <- as.factor(MovieLenseEDA_Joined$rating)

# Dataframe Uebersicht
MovieLenseEDA_Joined %>% group_by(rating) %>%
  summarize(Anzahl = n())

# Visuelle Darstellung mittels Barplot
MovieLenseEDA_Joined %>% group_by(rating) %>%
  summarize(Anzahl = n()) %>% 
  ggplot(aes(x = rating, y = Anzahl)) + 
  geom_bar(stat = "identity", 
           fill = "lightblue", 
           color = "black") + 
  labs(x = "Ratings", 
       y = "Anzahl", 
       title = "Verteilung der Kundenratings Gesamthaft",
       subtitle = paste("Gesamte Anzahl Kundenratings:", dim(MovieLenseEDA_Joined)[1]))
```
Wie wir in im Dataframe sowie im Barplot erkennen, werden Bewertungen 4 und 3 am häufigsten vergeben. Rating von 1 und 2 kommen deutlich weniger vor, als möglicher Grund könnte sein, dass Filme die schlecht sind gar nicht bewertet wurden, da man sich nicht mehr weiter mit schlechten Filmen befassen möchte. Aus eigenen Erfahrungen können wir sagen, dass man eher mehr bereit ist einen Film zu bewerten, wenn diese auch wirklich gut ist.  

### 1.2.2 Verteilung der Kundenratings nach Genre
```{r, fig.width = 10, fig.height = 10}
MovieLenseEDA_Joined$rating <- as.integer(MovieLenseEDA_Joined$rating)

MovieLenseEDA_Joined %>% 
  select(-c("item", "user", "year", "url")) %>% 
  pivot_longer(cols=c("unknown", "Action", "Adventure", "Animation", "Children's",
                      "Comedy", "Crime", "Documentary", "Drama", "Fantasy",
                      "Film-Noir", "Horror", "Musical", "Mystery", "Horror",
                      "Musical", "Mystery", "Romance", "Sci-Fi", "Thriller",
                      "War", "Western"),
               names_to = "Genre", values_to = "is_genre") %>%
  filter(is_genre == 1) %>% 
  ggplot(aes(x = rating)) +
  geom_bar(fill = "lightblue", color = "black") +
  labs(x = "Ratings", 
       y = "Anzahl", 
       title = "Verteilung der Kundenratings nach Genre",
       subtitle = paste("Gesamte Anzahl Kundenratings:", dim(MovieLenseEDA_Joined)[1])) + 
  facet_wrap(~Genre)
```
In der Visualisierung der Verteilung der Kundenratings pro Genre erkennen wir analog, wie bei der Verteilung der Gesamthaften Kundenratings, dass vorallem die Rating 3 und 4 am meisten vergeben werden.  

## 1.3 Wie verteilen sich die mittleren Kundenratings pro Film?
```{r}
# Dataframe
MovieLenseEDA %>% 
  group_by(item) %>% 
  summarize(mean_rating_per_film = mean(rating),
            n_rating_per_film = n()) %>% 
  arrange(n_rating_per_film)

# Visualisierung
MovieLenseEDA %>% 
  group_by(item) %>% 
  summarize(mean_rating_per_film = mean(rating)) %>% 
  ggplot(aes(x = mean_rating_per_film)) + 
  geom_histogram(color = "black", fill = "lightblue", binwidth = 0.1) +
    labs(x = "Ratings", 
       y = "Anzahl", 
       title = "Verteilung der Mittleren Kundenratings pro Film",
       subtitle = paste("Gesamte Anzahl Kundenratings:", dim(MovieLenseEDA)[1]))
```
Wir erkennen im Plot die Verteilung durchschnittliche Rating pro Film. Bei den Natürlichen Zahlen erkennen wir, dass dort die Anzahl deutlich höher ist als vom Rest. Dies liegt daran, dass es Filme gibt die nur eine oder wenige Bewertungen bekommen haben (siehe ausgegebenes Datafarme). Die meisten durchschnittlichen Rating pro Filme befinden sich im Rating Bereich von 3 bis 4. 

## 1.4 Wie stark streuen die Ratings von individuellen Kunden?
```{r, warning=FALSE}
MovieLenseEDA %>% filter(user == c(1:9)) %>% 
  ggplot(aes(x = user, y = rating)) +
  geom_violin(color = "black", fill = "lightblue") +
  labs(x = "User", 
       y = "Ratings", 
       title = "Streueung der Ratings von individuellen Kunden",
       subtitle = "MovieLenseData, Kunden 1-9")
```
Im Violinenplot erkennen wir die ersten 9 User und deren Rating Verteilungen mittels Violinenplot. Wir erkennen im Plot, dass sich User 2 und 8 ähnliche Filme bewerten. Beide Bewerten Filme öfters mit einer 4 und eher weniger eine 3 und 5, aber nie 2 und 1. 

## 1.5 Welchen Einfluss hat die Normierung der Ratings pro Kunde auf deren Verteilung?
```{r, warning=FALSE}
MovieLensenormalized <- normalize(MovieLense)
MovieLenseEDA_Normalized <- (as(MovieLensenormalized, "data.frame"))

MovieLenseEDA_Normalized %>% filter(user == c(1:9)) %>% 
  ggplot(aes(x = user, y = rating)) +
  geom_violin(color = "black", fill = "lightblue") +
  labs(x = "User", 
       y = "Normalisierte Ratings", 
       title = "Normalisierte Streueung der Ratings von individuellen Kunden",
       subtitle = "MovieLenseData, Kunden 1 - 9")
```
Durch die Normierung der Kundenratings verschiebt sich die y-Achse. Der neue Mittelwert der Ratings ist nun 0. Die Plots bleiben identisch wie zuvor, abgsehen von der Verschiebung der y-Achse.

## 1.6 Welche strukturellen Charakteristika (z.B. Sparsity) und Auffälligkeiten zeigt die User-Item Matrix?
```{r}
image(x = MovieLense, 
      xlab = "Items", 
      ylab = "Users", 
      main = "Sparisty 943 x 1664 User-Item Matrix 943 x 1664") 

image(MovieLense[1:50,1:50],
      xlab = "Items",
      ylab = "Users", 
      main = "Sparisty 50 x 50 User-Item Matrix")

# nratings(MovieLense) zaehlt die Anzahl vorhandenen Kombinationen von User und Items
(nratings(MovieLense) / (dim(MovieLense)[1] * dim(MovieLense)[2]) * 100)
```
Jede Zeile von MovieLense entspricht einem Benutzer und jede Spalte einem Film. Gesamthaft gibt es 943 x 1664 = 1’569’152 Kombinationen zwischen User und Film. Allerdings hat nicht jeder Nutzer jeden Film gesehen, aus diesem Grund ist es wichtig die Sparisy Matrix zu betrachten. In MovieLense Matrix fehlen ca. 94% der Kombinationen. Ca. 6 % ist die Sparse Matrix gefüllt mit Werten. 

# 2 Datenreduktion
Aufgabe 2: Reduziere den MovieLense Datensatz auf rund 400 Kunden und 700 Filme, indem du Filme und Kunden mit sehr wenigen Ratings entfernst.

## 2.1 Vorbereitung
### 2.1.1 DataFrame neu einlesen
```{r}
MovieLenseToCut <- as(MovieLense, "data.frame")
MovieLenseToCut
```

### 2.1.2 Auswahl der 400 Kunden
```{r}
select_user_400 <- function(movie_df, start, end) {
  selected_user <- movie_df %>% 
    group_by(user) %>% 
    summarize(Anzahl = n()) %>% 
    arrange(desc(Anzahl)) %>% 
    slice(start:end)
  selected_user
}

MovieLense400User_1 <- select_user_400(MovieLenseToCut, 0, 400)
MovieLense400User_1

MovieLense400User_2 <- select_user_400(MovieLenseToCut, 200, 599)
MovieLense400User_2
```

### 2.1.3 Auswahl der 700 Movies
```{r}
select_item_700 <- function(movie_df, start, end) {
  selected_item <- MovieLenseToCut %>% 
  group_by(item) %>% 
  summarise(Anzahl = n()) %>% 
  arrange(desc(Anzahl)) %>% 
  slice(start:end)
}

MovieLense700Items_1 <- select_item_700(MovieLenseToCut, 0, 700)
MovieLense700Items_1

MovieLense700Items_2 <- select_item_700(MovieLenseToCut, 150, 849)
MovieLense700Items_2

```

### 2.1.4 DataFrame schneiden
```{r}
df_cutter <- function(movie_df, selected_user, selected_items) {
  movie_df_cut <- movie_df %>%
      filter(user %in% c(selected_user$user))
  movie_df_cut <- movie_df_cut %>% 
      filter(item %in% c(selected_items$item))
  movie_df_cut
}

MovieLenseCut_1 <- df_cutter(MovieLenseToCut, MovieLense400User_1, MovieLense700Items_1)
MovieLenseCut_1

MovieLenseCut_2 <- df_cutter(MovieLenseToCut, MovieLense400User_2, MovieLense700Items_2)
MovieLenseCut_2
```

Untersuche und dokumentiere die Eigenschaften des reduzierten Datensatzes und beschreibe den Effekt der Datenreduktion, d.h.

## 2.2 Anzahl Filme und Kunden sowie Sparsity vor und nach Datenreduktion,
### 2.2.1 Vor der Datenreduktion
```{r}
image(MovieLense, 
      xlab = "Items", 
      ylab = "Users", 
      main = "Vor Datenreduktion, User-Item Matrix 943 x 1664") 

sparsity_text <- function(realrating_matrix) {
  print(paste("Anzahl vorhandene User-Item Rating in", nratings(realrating_matrix) / (dim(realrating_matrix)[1] * dim(realrating_matrix)[2]) * 100, "%"))
  print(paste("Sparsity der Matrix", 100 - (nratings(realrating_matrix) / (dim(realrating_matrix)[1] * dim(realrating_matrix)[2]) * 100), "%"))
}

sparsity_text(MovieLense)

```



### 2.2.2 Nach der 1. Datenreduktion
```{r}
MovieLenseCompact_1 <- as(MovieLenseCut_1, "realRatingMatrix")
image(MovieLenseCompact_1,
      xlab = "Items", 
      ylab = "Users", 
      main = "Nach Datenreduktion 1, User-Item Matrix 400 x 700")

sparsity_text(MovieLenseCompact_1)
```

### 2.2.3 Nach der 2. Datenreduktion
```{r}
MovieLenseCompact_2 <- as(MovieLenseCut_2, "realRatingMatrix")
image(MovieLenseCompact_2,
      xlab = "Items", 
      ylab = "Users", 
      main = "Nach Datenreduktion 2, User-Item Matrix 400 x 700")

sparsity_text(MovieLenseCompact_2)

```

Wir haben unseren Datensatz zur gleichen Anzahl User und Item reduziert. Obwohl die Anzahl an User und Item bei beiden Reduktionen identisch ist, ist die Sparsity der Matrix deutlich unterschiedlich. Bei der ersten Reduktion haben wir die meisten 400 User 700 Items ausgewaehlt. Dies fuherte zu einer Sparsity von 76%. Verglichen zur Ursprünglichen Sparsity von 94%, ist dies eine deutliche Reduktion. Dies erkennen wir ebenfalls in der Visualisierung. Bei der zweiten Reduktion hat sich die Sparsity im zweite Komma stellen Bereich veraendert. Diese liegt immer noch wie bei der ursprünglichen Matrix bei 94%. 

## 2.3 Mittlere Kundenratings pro Film vor und nach Datenreduktion,
```{r}
mean_rating_per_film_viz <- function(movie_df) {
  movie_df %>% 
  group_by(item) %>% 
  summarize(mean_rating_per_film = mean(rating)) %>% 
  ggplot(aes(x = mean_rating_per_film)) + 
  geom_histogram(color = "black", fill = "lightblue", binwidth = 0.1) +
    labs(x = "Ratings", 
       y = "Anzahl", 
       title = "Mittlere Kundenratings Verteilung",
       subtitle = paste("Gesamte Anzahl Kundenratings:", dim(movie_df)[1])) +
    geom_vline(xintercept = mean(movie_df$rating), color = "red", linetype = "dashed", size = 0.5)
}
# Vor reduktion
print(mean_rating_per_film_viz(MovieLenseEDA))
# nach 1. Redutkion
print(mean_rating_per_film_viz(MovieLenseCut_1))
# nach 2. Reduktion
print(mean_rating_per_film_viz(MovieLenseCut_2))
```
In den Visualisierungen erkennen wir, das sich der Mittelwert der Gesamten Kundenrating für den ursprünglichen sowie auch für die beiden Reduzierten Datensätze nicht grossartig ändert. Diese befindet sich bei allen im Bereich von 3.5. Was aber erkennbar ist bei der 1. Reduktion ist, dass die hohe Anzahl Rating bei den Natürlichen Zahlen weg gefallen sind, dies aufgrund der Reduktion. Weiterhin sind bei allen Visualisuerungen die meisten Rating im Bereich von 3 bis 4. 

## 2.4 Für Gruppen: Quantifiziere “Intersection over Union” der Ratings der unterschiedlich reduzierten Datensätze.
```{r}
intersect_join <- inner_join(MovieLenseCut_1, MovieLenseCut_2, by = c("user", "item"))
intersect_join

union_join <- full_join(MovieLenseCut_1, MovieLenseCut_2, by = c("user", "item"))
union_join

paste("Eine Intersection over Union von", dim(intersect_join)[1] / dim(union_join)[1] * 100, "%, zwischen den beiden reduzierten Datensätzen")

```

15.6% überschneidungen gibt es zwischen den beiden reduzierten Datensätzen. 

# 3 Analyse Ähnlichkeitsmatrix
Aufgabe 3: Erzeuge einen IBCF Recommender und analysiere die Ähnlichkeitsmatrix des trainierten Modelles für den reduzierten Datensatz.

## 3.1 Zerlege den reduzierten MovieLense Datensatz in ein disjunktes Trainings-und Testdatenset im Verhältnis 4:1,
```{r}
train_test_split <- function(movie_df, split = 0.8) {
  n <- dim(movie_df)[1]
  n_train <- round(n * split)
  n_test <- n - n_train
  training <- movie_df[1:n_train]
  test <- movie_df[(n_train + 1):n]
  return(list(training, test))
}

train_test_list_1 <- train_test_split(MovieLenseCompact_1)
training_1 <- train_test_list_1[[1]]
test_1 <- train_test_list_1[[2]]
training_1
test_1

train_test_list_2 <- train_test_split(MovieLenseCompact_2)
training_2 <- train_test_list_2[[1]]
test_2 <- train_test_list_2[[2]]
training_2
test_2

```
Beide reduzierten Datensaetze wurden im Verhaletnis 4:1, (4 Teile Training und 1 Teil Test) reduziert.

## 3.2 Trainiere ein IBCF Modell mit 30 Nachbarn und Cosine Similarity
```{r}
ribcf_1 <- Recommender(training_1, "IBCF", param=list(k= 30, method = "cosine"))
ribcf_1

ribcf_2 <- Recommender(training_2, "IBCF", param=list(k= 30, method = "cosine"))
ribcf_2
```
Es wurden jeweils fuer beide reduzierten Datensaetze ein ribcf Modell trainiert mit dem recommenderlab zur Verfuegung gestellte Methode.

## 3.3 Bestimme die Verteilung der Filme, welche bei IBCF für paarweise Ähnlichkeitsvergleiche verwendet werden
```{r}
ribcf_sim_item_df <- function(ribcf) {
  # model
  ribcf_model <- getModel(ribcf)
  # dataframe erstellen
  ribcf_sim_df <- as.data.frame(colSums(ribcf_model$sim > 0))
  # Item als neue Spalte hinzufuegen und Index entfernen
  ribcf_sim_df_ <- cbind(item = rownames(ribcf_sim_df), ribcf_sim_df)
  rownames(ribcf_sim_df_) <- NULL
  # return df
  ribcf_sim_df_
}

ribcf_sim_viz <- function(ribcf_sim_df_, n_reduc) {
    ribcf_sim_df_ %>%
    rename(Anzahl = 2) %>% 
    ggplot(aes(x = Anzahl)) + 
    geom_histogram(binwidth =  0.1) +
    labs(title = "Verteilung der Ähnlichkeitsvergleiche",
         x = "Anzahl Filme als Nachbar", 
         y = "Anzahl",
         subtitle = paste("ribcf", n_reduc))
}

ribcf_sim_df_1 <- ribcf_sim_item_df(ribcf_1)
ribcf_sim_viz(ribcf_sim_df_1, 1)

ribcf_sim_df_2 <- ribcf_sim_item_df(ribcf_2)
ribcf_sim_viz(ribcf_sim_df_2, 2)


```
Im Histogramm erkennt man die Anzahl Filme die als Nachbar bei einem anderen Film auftauchen. Beide Plots sind deutlich unterschiedlich

## 3.4 Bestimme die Filme, die am häufigsten in der Cosine-Ähnlichkeitsmatrix auftauchen und analysiere deren Vorkommen und Ratings im reduzierten Datensatz.

```{r, warning=FALSE}
top_10_item_sim <- function(ribcf_sim_df_, n_reduc) {
  result <- ribcf_sim_df_ %>% 
  rename(Anzahl = 2) %>% 
  arrange(desc(Anzahl)) %>% 
  top_n(10)
    
  print(result)
    
  result %>%   
  ggplot(aes(x = Anzahl, y = item)) +
  # arrange desc
  geom_col(alpha = 0.5, color = "black", fill = "limegreen") +
  labs(title = "Top 10 Filme die am häufigsten in der Nachbarschaft andere Filme auftauchen",
       x = "Anzahl Film als Nachbar", 
       y = "Filme",
       subtitle = paste("ribcf", n_reduc))
}
  
top_10_item_sim(ribcf_sim_df_1, 1)
top_10_item_sim(ribcf_sim_df_2, 2)

```

Top 10 Filme die am haeufigesten in der Nachbarschaft andere Filme auftauchen.

# 4 Implementierung Ähnlichkeitsmatrix
Aufgabe 4 (DIY): Implementiere eine Funktion zur effizienten
Berechnung von sparsen Ähnlichkeitsmatrizen für IBCF RS und
analysiere die Resultate für 100 zufällig gewählte Filme.

## 4.1 Implementiere eine Funktion, um (a) für ordinale Ratings effizient
die Cosine Similarity und (b) für binäre Ratings effizient die Jaccard
Similarity zu berechnen,
```{r}
number_user <- 100
number_item <- 100
```

### 4.1.1 Cosine Similarity 
```{r}
get_cossim_4 <- function(RatingMatrix, n_user, n_item){
 
  sliced_matrix <- getRatingMatrix(RatingMatrix[1:n_user, 1:n_item])
  
  sliced_matrix_t <- t(sliced_matrix)
  
  temp_sim <- sliced_matrix_t / sqrt(rowSums(sliced_matrix_t ** 2))

  cossim_matrix <- temp_sim %*% t(temp_sim)

  cossim_matrix
}
```

```{r}
result_cossim_4 <- get_cossim_4(MovieLense, number_user, number_item)
result_cossim_4[1:5,1:5]
```

### 4.1.2 Jaccard Similarity
```{r}
get_jaccardsim_4 <- function(RatingMatrix, n_user, n_item){
  
  sliced_matrix_bin <- as(binarize(RatingMatrix[1:n_user, 1:n_item], minRating=4), "matrix")
  
  sliced_matrix_bin_t <- t(sliced_matrix_bin)
  
  matrix_corssprod <- tcrossprod(sliced_matrix_bin_t)
  
  im <- which(matrix_corssprod > 0, arr.ind=TRUE)
  b <- rowSums(sliced_matrix_bin_t)
  Aim <- matrix_corssprod[im]
  
  J = sparseMatrix(
            i = im[,1],
            j = im[,2],
            x = Aim / (b[im[,1]] + b[im[,2]] - Aim),
            dims = dim(matrix_corssprod)
      )
  
  J <- data.matrix(J)
  
  J
}

```

```{r}
get_jaccardsim_4(MovieLense, number_user, number_item)
```

## 4.2 Vergleiche deine Implementierung der Cosine-basierten
Ähnlichkeitsmatrix für ordinale Ratings mit der via recommenderlab
und einem anderen R-Paket erzeugten Ähnlichkeitsmatrix,
```{r}

```

### 4.2.1 Vergleich Cosine Similiarty mit Recommenderlab
```{r}
recom_simcosin_4 <- as.matrix(similarity(normalize(MovieLense[1:number_user, 1:number_item]), which = "items", method = "cosine"))

recom_simcosin_4[1:4,1:4]
```

```{r}
result_cossim_4_scaled <- 1 / 2 * (result_cossim_4 + 1)

result_cossim_4_scaled[1:4,1:4]
```

### 4.2.2 Vergleich Cosine Similiarity mit anderem R-Paket
```{r}
library(lsa)

rec_simMat <- similarity(MovieLenseCompact_1[,1:3], which = "items")
rec_simMat

# simMat_lsa <- cosine(DfforSimMatrix, y = NULL)
```

## 4.3 Vergleiche deine mittels Cosine Similarity erzeugten Ähnlichkeitsmatrix für ordinale Ratings mit der Jaccard-basierten
Ähnlichkeitsmatrix für binäre Ratings.
```{r}

```


# 5 Analyse Top-N Listen - IBCF vs UBCF
Aufgabe 5: Vergleiche und diskutiere Top-N Empfehlungen von IBCF
und UBCF Modellen mit 30 Nachbarn und Cosine Similarity für den
reduzierten Datensatz.
## 5.1 Berechne Top-15 Empfehlungen für Testkunden mit IBCF und UBCF 
### 5.1.1 ribcf & rubcf Modell trainieren
```{r}
ribcf_1 <- Recommender(training_1, "IBCF", param=list(k= 30, method = "cosine"))
ribcf_1

rubcf_1 <- Recommender(training_1, "UBCF", param=list(nn= 30, method = "cosine"))
rubcf_1
```

```{r}
ribcf_2 <- Recommender(training_2, "IBCF", param=list(k= 30, method = "cosine"))
ribcf_2

rubcf_2 <- Recommender(training_2, "UBCF", param=list(nn= 30, method = "cosine"))
rubcf_2
```
Es wurden fuer beide reduzierten Datensaetze jeweils ein ribcf und ubcf recommender erstellt. 

### 5.1.2 Model Predicitions erstellen
```{r}
ribcftopNList_1 <- predict(ribcf_1, test_1, n=15)
ribcftopNList_1

rubcftopNList_1 <- predict(rubcf_1, test_1, n=15)
rubcftopNList_1

ribcftopNList_2 <- predict(ribcf_2, test_2, n=15)
ribcftopNList_2

rubcftopNList_2 <- predict(rubcf_2, test_2, n=15)
rubcftopNList_2
```

### 5.1.3 Ausgabe von einer Prediction
```{r}
# ausgabe von einem output
as(ribcftopNList_1, "list")
```


## 5.2 Vergleiche die Top-15 Empfehlungen und deren Verteilung und
diskutiere Gemeinsamkeiten und Unterschiede zwischen IBCF und
UBCF für alle Testkunden.

```{r}
# df funktion erstellen
topN_df <- function(topNList){
  counts <- table(unlist(as.array(as(topNList, "list"))))
  df <- data.frame(Movie = names(counts), Count = unname(counts)) %>%
    select("Movie", "Count.Freq") %>%
    rename("Count" = "Count.Freq") %>%
    arrange(desc(Count))  
  df
}

# alle dfs erstellen
ribcftopN_df_1 <- topN_df(ribcftopNList_1)
ribcftopN_df_1
ribcftopN_df_2 <- topN_df(ribcftopNList_2)
ribcftopN_df_2

rubcftopN_df_1 <- topN_df(rubcftopNList_1)
rubcftopN_df_1
rubcftopN_df_2 <- topN_df(rubcftopNList_2)
rubcftopN_df_2

```


### 5.2.1 Verteilungen visualisieren
```{r, fig.height=8, fig.width=15}
# funktion zur Visualisierung
top15_df_visualize <- function(topNList, subtitle){
  topNList %>% head(15) %>% 
    ggplot(aes(x = reorder(Movie, Count), y = Count)) +
    geom_bar(stat = "identity", fill = "limegreen", alpha = 0.5, color = "black") +
    coord_flip() +
    labs(x = "Movie", 
         y = "Anzahl", 
         title = "Top-15 Empfehlungen",
         subtitle = subtitle)
}

grid.arrange(top15_df_visualize(ribcftopN_df_1, "ribcf 1"),
             top15_df_visualize(rubcftopN_df_1, "rubcf 1"),
             ncol = 2)


grid.arrange(top15_df_visualize(ribcftopN_df_2, "ribcf 2"),
             top15_df_visualize(rubcftopN_df_2, "rubcf 2"),
             ncol = 2)

```
Die erwähnte Behauptung “Recommender Systeme machen für alle Nutzer die gleichen Empfehlungen” kann dank dieser Histogramme verworfen werden. Sehr viele Filme werden nur wenigen User (<4) empfohlen.
Weiterer Text folgt.


# 6 Analyse Top-N Listen - Ratings
Aufgabe 6: Untersuche den Einfluss von Ratings (ordinale vs binäre Ratings) und Modelltyp (IBCF vs UBCF) auf Top-N Empfehlungen für den reduzierten Datensatz. Vergleiche den Anteil übereinstimmender Empfehlungen der Top-15 Liste für
## 6.1 IBCF vs UBCF, beide mit ordinalem Rating und Cosine Similarity für alle Testkunden,
```{r}
compare_ibcf_ubcf <- function(ibcf, ubcf) {
  print(paste("Anzahl IBCF:", nrow(ibcf)))
  print(paste("Anzahl UBCF:", nrow(ubcf)))

  IntersectordRatCosine <- intersect(ibcf$Movie, ubcf$Movie)

  print(paste("Anzahl gemeinsame Empfehlungen:", length(IntersectordRatCosine)))
  print(paste("Anteil IBCF:", length(IntersectordRatCosine) / nrow(ibcf) * 100))
  print(paste("Anteil UBCF:", length(IntersectordRatCosine) / nrow(ubcf) * 100))
}

print("Erste Datenreduktion")
compare_ibcf_ubcf(ribcftopN_df_1, rubcftopN_df_1)
print("Zweite Datenreduktion")
compare_ibcf_ubcf(ribcftopN_df_2, rubcftopN_df_2)
```

## 6.2 IBCF vs UBCF, beide mit binärem Rating und Jaccard Similarity für alle Testkunden,
```{r}
training_bin_1 <- binarize(training_1, minRating = 4)
test_bin_1 <- binarize(test_1, minRating = 4)

training_bin_2 <- binarize(training_2, minRating = 4)
test_bin_2 <- binarize(test_2, minRating = 4)

ribcf_bin_1 <- Recommender(training_bin_1, "IBCF", param=list(k= 30, method = "jaccard"))
ribcf_bin_1

rubcf_bin_1 <- Recommender(training_bin_1, "UBCF", param=list(nn= 30, method = "jaccard"))
rubcf_bin_1

ribcf_bin_2 <- Recommender(training_bin_2, "IBCF", param=list(k= 30, method = "jaccard"))
ribcf_bin_2

rubcf_bin_2 <- Recommender(training_bin_2, "UBCF", param=list(nn= 30, method = "jaccard"))
rubcf_bin_2

```

```{r}
ribcftopNList_bin_1 = predict(ribcf_bin_1, test_bin_1, n=15)
ribcftopNList_bin_1

rubcftopNList_bin_1 = predict(rubcf_bin_1, test_bin_1, n=15)
rubcftopNList_bin_1

ribcftopNList_bin_2 = predict(ribcf_bin_2, test_bin_2, n=15)
ribcftopNList_bin_2

rubcftopNList_bin_2 = predict(rubcf_bin_2, test_bin_2, n=15)
rubcftopNList_bin_2
```

```{r}
ribcftopN_df_bin_1 <- topN_df(ribcftopNList_bin_1)
ribcftopN_df_bin_1

rubcftopN_df_bin_1 <- topN_df(rubcftopNList_bin_1)
rubcftopN_df_bin_1

ribcftopN_df_bin_2 <- topN_df(ribcftopNList_bin_2)
ribcftopN_df_bin_2

rubcftopN_df_bin_2 <- topN_df(rubcftopNList_bin_2)
rubcftopN_df_bin_2

```

```{r}
print("Erste Datenreduktion binaer")
compare_ibcf_ubcf(ribcftopN_df_bin_1, rubcftopN_df_bin_1)
print("Zweite Datenreduktion binaer")
compare_ibcf_ubcf(ribcftopN_df_bin_2, rubcftopN_df_bin_2)
```
Zu diskutieren: Wieso sind die Anzahl Übereinstimmungen am höchsten sind, wenn minRating 5 ist.

## 6.3 UBCF mit ordinalem (Cosine Similarity) vs UBCF mit binärem Rating (Jaccard Similarity) für alle Testkunden.
```{r}
print("Erste Datenreduktion")
compare_ibcf_ubcf(rubcftopN_df_1, rubcftopN_df_bin_1)
print("Zweite Datenreduktion")
compare_ibcf_ubcf(rubcftopN_df_2, rubcftopN_df_bin_2)
```

```{r}
#Histogramm der Vergleiche
```

# 7 Analyse Top-N Listen - IBCF vs SVD
Aufgabe 7: Vergleiche
Memory-based IBCF und Modell-based SVD Recommenders bezüglich Überschneidung ihrer Top-N Empfehlungen für die User-Item Matrix des reduzierten Datensatzes (Basis: reduzierter Datensatz, IBCF mit 30 Nachbarn und Cosine Similarity).
Vergleiche wie sich der Anteil übereinstimmender Empfehlungen der Top-15 Liste für IBCF vs verschiedene SVD Modelle verändert, wenn die Anzahl der Singulärwerte für SVD von 10 auf 20, 30, 40, 50 verändert wird.
```{r}
# Funktion fuer SVD Model
generate_SVD_topN_recomm <- function(train, test, svd_value = ksvd){
	recom_model <- Recommender(train, "SVD", param=list(k= svd_value))
	top_n_recom <- predict(recom_model, test, n=15)
  top_n_recom
}

# Funktion fuer verschiedene N
generate_SVD_topN_lists <- function(train, test, N_values) {
  rsvd_topN_lists <- list()
  for (i in 1:length(N_values)) {
    N <- N_values[i]
    list_name <- paste0("rsvd", N, "topNList")
    rsvd_topN_lists[[list_name]] <- generate_SVD_topN_recomm(train, test, N)
  }
  rsvd_topN_lists
}
```


```{r}
N_values <- c(10, 20, 30, 40, 50)
rsvd_topN_lists_1 <- generate_SVD_topN_lists(training_1, test_1, N_values)
print("Erster Datensatz")
rsvd_topN_lists_1

rsvd_topN_lists_2 <- generate_SVD_topN_lists(training_2, test_2, N_values)
print("Zweiter Datensatz")
rsvd_topN_lists_2
```


```{r}
# alternative... 
#rsvd10topN_df_1 <- topN_df(rsvd_topN_lists_1$rsvd10topNList)
#rsvd20topN_df_1 <- topN_df(rsvd_topN_lists_1$rsvd20topNList)
#rsvd30topN_df_1 <- topN_df(rsvd_topN_lists_1$rsvd30topNList)
#rsvd40topN_df_1 <- topN_df(rsvd_topN_lists_1$rsvd40topNList)
#rsvd50topN_df_1 <- topN_df(rsvd_topN_lists_1$rsvd50topNList)

#rsvd10topN_df_2 <- topN_df(rsvd_topN_lists_2$rsvd10topNList)
#rsvd20topN_df_2 <- topN_df(rsvd_topN_lists_2$rsvd20topNList)
#rsvd30topN_df_2 <- topN_df(rsvd_topN_lists_2$rsvd30topNList)
#rsvd40topN_df_2 <- topN_df(rsvd_topN_lists_2$rsvd40topNList)
#rsvd50topN_df_2 <- topN_df(rsvd_topN_lists_2$rsvd50topNList)

# mittels forloop :)
generate_topN_dfs <- function(rsvd_topN_lists) {
  topN_dfs <- list()
  
  for (i in 1:length(rsvd_topN_lists)) {
    list_name <- names(rsvd_topN_lists)[i]
    df_name <- paste0(list_name, "_df")
    topN_dfs[[df_name]] <- topN_df(rsvd_topN_lists[[i]])
  }
  
  topN_dfs
}

topN_df_svd_1 <- generate_topN_dfs(rsvd_topN_lists_1)
print("Erster Datensatz")
topN_df_svd_1

topN_df_svd_2 <- generate_topN_dfs(rsvd_topN_lists_2)
print("Zweiter Datensatz")
topN_df_svd_2


```

```{r}
compare_ibcf_svd <- function(ribcf, svd, svd_value) {
  intersect <- intersect(ribcf$Movie, svd$Movie)
  print(paste("Anzahl gemeinsame Empfehlungen SVD", svd_value, ":", length(intersect)))
  print(paste("Anteil", svd_value, ":", length(intersect) / nrow(ribcf) * 100))
}

print("Erster Datensatz")
compare_ibcf_svd(ribcftopN_df_1, topN_df_svd_1$rsvd10topNList_df, 10)
compare_ibcf_svd(ribcftopN_df_1, topN_df_svd_1$rsvd20topNList_df, 20)
compare_ibcf_svd(ribcftopN_df_1, topN_df_svd_1$rsvd30topNList_df, 30)
compare_ibcf_svd(ribcftopN_df_1, topN_df_svd_1$rsvd40topNList_df, 40)
compare_ibcf_svd(ribcftopN_df_1, topN_df_svd_1$rsvd50topNList_df, 50)

print("Zweiter Datensatz")
compare_ibcf_svd(ribcftopN_df_2, topN_df_svd_2$rsvd10topNList_df, 10)
compare_ibcf_svd(ribcftopN_df_2, topN_df_svd_2$rsvd20topNList_df, 20)
compare_ibcf_svd(ribcftopN_df_2, topN_df_svd_2$rsvd30topNList_df, 30)
compare_ibcf_svd(ribcftopN_df_2, topN_df_svd_2$rsvd40topNList_df, 40)
compare_ibcf_svd(ribcftopN_df_2, topN_df_svd_2$rsvd50topNList_df, 50)
```

# 8 Implementierung Top-N Metriken
Aufgabe 8 (DIY) 
## 8.1 CoverageN 
```{r}
ribcf_8 <- Recommender(MovieLense, "IBCF", param=list(k= 30, method = "cosine"))
ribcf_8

ribcftopNList_8 <- predict(ribcf_8, MovieLense, n=15)
ribcftopNList_8

list_items_8 <- unique(unlist(as(ribcftopNList_8, "list"), use.names = FALSE))
len_items_8 <- length(list_items_8)

len_all_items_8 <- dim(MovieLense)[2]
len_all_items_8

coverageN <- len_items_8 / len_all_items_8
coverageN
```
41.7 % der vorhandenen Filme werden empfohlen.

## 8.2 NoveltyN
```{r}
nratings(MovieLense) / len_all_items_8
```

# 9 Wahl des optimalen Recommenders
Aufgabe 9
## 9.1 Verwende für die Evaluierung 10-fache Kreuzvalidierung
```{r}
set.seed(1234)
scheme_1 <- evaluationScheme(MovieLenseCompact_1, method="cross-validation", k = 10, given=3, goodRating=5)
scheme_2 <- evaluationScheme(MovieLenseCompact_2, method="cross-validation", k = 10, given=3, goodRating=5)

print("Erste Datenreduktion")
scheme_1
print("Zweite Datenreduktion")
scheme_2


```

## 9.2 Begründe deine Wahl von Metriken und Modell
```{r}
algorithms <- list("hybrid" = list(name = "HYBRID", param =list(recommenders = list(SVD = list(name="SVD", param=list(k = 40)),
                                                                                    POPULAR = list(name = "POPULAR", param = NULL)
                                                                                    ))),
                   "libmf" = list(name="LIBMF", param=list(dim=10)),
                   "popular items" = list(name="POPULAR", param=NULL),
                   "user-based CF" = list(name="UBCF", param=list(nn=50)),
                   "item-based CF" = list(name="IBCF", param=list(k=50)),
                   "SVD40" = list(name="SVD", param=list(k = 40)))

print("Erster Datensatz")
results_1 <- evaluate(scheme_1, algorithms, type = "topNList", n=c(10, 15, 20, 25, 30))
print("Zweiter Datensatz")
results_2 <- evaluate(scheme_2, algorithms, type = "topNList", n=c(10, 15, 20, 25, 30))
```

```{r}
plot(results_1, annotate=c(1,3), legend="topleft")
plot(results_2, annotate=c(1,3), legend="topleft")
```

## 9.3 Analysiere das beste Modell für Top-N Recommendations mit N = 10, 15, 20, 25 und 30,
vieles blabaalabaaassss

## 9.4 Optimiere dein bestes Modell hinsichtlich Hyperparametern
```{r}
algorithmsimprovedrecom <- list("popular items center" = list(name="POPULAR", param=NULL),
                   "popular items Z-score" = list(name="POPULAR", param=list(normalize="Z-score")))

resultsimprovedrecom_1 <- evaluate(scheme_1, algorithmsimprovedrecom, type = "topNList", n=c(10, 15, 20, 25, 30))
resultsimprovedrecom_2 <- evaluate(scheme_2, algorithmsimprovedrecom, type = "topNList", n=c(10, 15, 20, 25, 30))
```

```{r}
plot(resultsimprovedrecom_1, annotate=c(1,3), legend="topleft")
plot(resultsimprovedrecom_2, annotate=c(1,3), legend="topleft")
```

Hinweis: Verwende für den Top-Movie Recommender die Filme mit den höchsten Durchschnittsratings.
# 10 Implementierung Top-N Monitor
Aufgabe 10 (DIY): Untersuche die relative Übereinstimmung zwischen
Top-N Empfehlungen und präferierten Filmen für 4 unterschiedliche
Modelle (z.B. IBCF und UBCF mit unterschiedlichen Ähnlichkeitsmetriken / Nachbarschaften sowie SVD mit unterschiedlicher
Dimensionalitätsreduktion).

## 10.1 Fixiere 20 zufällig gewählte Testkunden für alle Modellvergleiche,
```{r}
# select 20 random users
set.seed(1234)
testUsers <- sample(1:nrow(MovieLense), 20)
testUsers

# filter MovieLense by testUsers
MovieLenseTest <- MovieLense[testUsers,] 
MovieLenseTest
```

## 10.2 Bestimme den Anteil der Top-N Empfehlung nach Genres pro Kunde,
```{r}
# get from every TestUsers the Top_N item list
ribcf_10 <- Recommender(MovieLenseTest, "IBCF", param=list(k= 30, method = "cosine"))

# predict Top-N items for every user
ribcftopNList_10 <- predict(ribcf_10, MovieLenseTest, n=15)

# create a list with the topN items for every user
ribcftopNList_10_list <- as(ribcftopNList_10, "list")

# create a tibble with the topN items for every user
ribcftopNList_10_tibble <- as_tibble(ribcftopNList_10_list)

# transform the tibble to a data frame
ribcftopNList_10_df <- as.data.frame(ribcftopNList_10_tibble)

# replace colname with testUsers
colnames(ribcftopNList_10_df) <- testUsers

# transpose data frame
ribcftopNList_10_df_transposed <- t(ribcftopNList_10_df)

# change ribcftopNList_10_df_transposed to a tibble
ribcftopNList_10_df_transposed_tibble <- as_tibble(ribcftopNList_10_df_transposed)

# add a column with the testUsers
ribcftopNList_10_df_transposed_tibble$testUsers <- testUsers

# pivot longer dataframe
ribcftopNList_10_df_transposed_tibble_pivot <- pivot_longer(ribcftopNList_10_df_transposed_tibble, cols = 1:15, names_to = "topN", values_to = "itemID")

# get genre from each item
ribcftopNList_10_df_transposed_tibble_pivot_genre <- left_join(ribcftopNList_10_df_transposed_tibble_pivot, MovieLenseMeta, by = c("itemID" = "title"))
ribcftopNList_10_df_transposed_tibble_pivot_genre

# drop columns topN, year, url
ribcftopNList_10_df_transposed_tibble_pivot_genre <- select(ribcftopNList_10_df_transposed_tibble_pivot_genre, -topN, -year, -url, -itemID)
ribcftopNList_10_df_transposed_tibble_pivot_genre
```

```{r}
# pivot longer dataframe
ribcftopNList_10_df_transposed_tibble_pivot_genre %>% group_by(testUsers) %>%
  summarise(across(everything(), ~ sum(., is.na(.), 0)))
```



## 10.3 Bestimme pro Kunde den Anteil nach Genres seiner Top-Filme
(=Filme mit besten Bewertungen),
```{r}

```

## 10.4 Vergleiche pro Kunde Top-Empfehlungen vs Top-Filme nach Genres,
```{r}

```

## 10.5 Definiere eine Qualitätsmetrik für Top-N Listen und teste sie.
```{r}

```

