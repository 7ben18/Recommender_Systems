---
title: "RSY-MC1"
author: "Patrick, Ben"
output: 
  html_notebook:
    toc: True
    toc_float: True
---
# Mini-Challenge Beschreibung


# Daten und Libraries
```{r}
library(tidyverse)
library(recommenderlab)
```
## Daten einlesen
```{r}
data(MovieLense)
```

## Library Methoden zum Datensatz MovieLense
```{r}
methods(class = class(MovieLense))
```

## Kopfzeilen vom Datensatz ausgeben
```{r}
head(as(MovieLense, "data.frame"))
```

## Fusszeilen vom Datensatz ausgeben
```{r}
tail(as(MovieLense, "data.frame"))
```

## Info zum Datensatz
```{r}
summary(as(MovieLense, "data.frame"))
```
## Datenframe Variabel erstellen
```{r}
MovieLenseEDA <- as(MovieLense, "data.frame")
```


# Explorative Datenanalyse
Aufgabe 1: Untersuche den vollständigen MovieLense Datensatz 
(d.h. vor Datenreduktion!) und beantworte folgende Fragen

## 1. Welches sind die am häufigsten geschauten Genres/Filme?

### Filme
```{r}
MovieLenseEDA %>% 
  group_by(item) %>% 
  summarise(Anzahl = n()) %>%
  arrange(desc(Anzahl)) 
```

### Genre
```{r}
# Full Join mit df_movies_rating und MovieLenseMeta
MovieLenseEDA_Joined <- full_join(MovieLenseEDA, MovieLenseMeta, 
          by = c("item" = "title")) %>% 
  select(-c("user", "item", "rating", "year", "url")) 

# Aufsummieren der Genre Spalten
(colSums(MovieLenseEDA_Joined)) %>% sort(decreasing = TRUE)

### 
# Muessen wir Genre Unknown entfernen?
```

## 2. Wie verteilen sich die Kundenratings gesamthaft und nach Genres?
```{r}
# DataFrame join
MovieLenseEDA_Joined <- full_join(MovieLenseEDA, MovieLenseMeta, 
          by = c("item" = "title"))
```

### Verteilung der Kundenratings Gesamthaft
```{r}
MovieLenseEDA_Joined$rating <- as.factor(MovieLenseEDA_Joined$rating)

MovieLenseEDA_Joined %>% group_by(rating) %>%
  summarize(Anzahl = n()) %>% 
  ggplot(aes(x = rating, y = Anzahl)) + 
  geom_bar(stat = "identity", 
           fill = "lightblue", 
           color = "black") + 
  labs(x = "Ratings", 
       y = "Anzahl", 
       title = "Kundenratings Gesamthaft",
       subtitle = "MovieLenseData")
```

### Verteilung der Kundenratings nach Genre
```{r}
MovieLenseEDA_Joined$rating <- as.integer(MovieLenseEDA_Joined$rating)

MovieLenseEDA_Joined %>% 
  select(-c("item", "user", "year", "url")) %>% 
  pivot_longer(cols=c("unknown", "Action", "Adventure", "Animation", "Children's",
                      "Comedy", "Crime", "Documentary", "Drama", "Fantasy",
                      "Film-Noir", "Horror", "Musical", "Mystery", "Horror",
                      "Musical", "Mystery", "Romance", "Sci-Fi", "Thriller",
                      "War", "Western"),
               names_to = "Genre", values_to = "is_genre") %>%
  filter(is_genre == 1) %>% 
  ggplot(aes(x = rating)) +
  geom_bar(fill = "lightblue", color = "black") + 
  facet_wrap(~Genre)
```

```{r}


MovieLenseHistoGenreRating <- MovieLenseEDA_Joined %>% 
  select(-c("item", "user", "year", "url")) %>% 
  pivot_longer(cols=c("unknown", "Action", "Adventure", "Animation", "Children's",
                      "Comedy", "Crime", "Documentary", "Drama", "Fantasy",
                      "Film-Noir", "Horror", "Musical", "Mystery", "Horror",
                      "Musical", "Mystery", "Romance", "Sci-Fi", "Thriller",
                      "War", "Western"),
               names_to = "Genre", values_to = "X") %>%
  group_by(Genre, rating) %>%
  summarize(Anzahl = n()) 
  
MovieLenseHistoGenreRating$rating <- as.factor(MovieLenseHistoGenreRating$rating)

MovieLenseHistoGenreRating 
# ToDO Vis fehlt
```


## 3. Wie verteilen sich die mittleren Kundenratings pro Film?
```{r}
MovieLenseEDA %>% 
  group_by(item) %>% 
  summarize(mean_rating_per_film = mean(rating)) %>% 
  ggplot(aes(x = mean_rating_per_film)) + 
  geom_histogram(color = "black", fill = "lightblue", binwidth = 0.5) +
    labs(x = "Ratings", 
       y = "Anzahl", 
       title = "Mittlere Kundenratings verteilung",
       subtitle = "MovieLenseData")

```

## 4. Wie stark streuen die Ratings von individuellen Kunden?
```{r}
MovieLenseEDA %>% filter(user == c(1:9)) %>% 
  ggplot(aes(x = user, y = rating)) +
  geom_violin(color = "black", fill = "lightblue") 

# Beschriftung und Farbe
```

## 5. Welchen Einfluss hat die Normierung der Ratings pro Kunde auf deren Verteilung?
```{r}
MovieLensenormalized <- normalize(MovieLense)
MovieLenseEDA_Normalized <- (as(MovieLensenormalized, "data.frame"))

MovieLenseEDA_Normalized %>% filter(user == c(1:9)) %>% 
  ggplot(aes(x = user, y = rating)) +
  geom_violin(color = "black", fill = "lightblue") 

# Labelings & Interpreation

```

## 6. Welche strukturellen Charakteristika (z.B. Sparsity) und Auffälligkeiten zeigt die User-Item Matrix?
```{r}
image(MovieLense) 

# Labeling + Interpreation + Antwort fehlt. 
# Aufsteigend nach Anzahl bewertete Filmen
# Film Besonders die ersten 400 Filme wurden am meisten bewrtet.
# User kein Muster erkennbar
```

```{r}
# nratings => Gibt mir die Anzahl Bewerteten Filme in der Matrix
# dim(MovieLense) gibt mir die Dimension (Zeilen, Spalten)

nratings(MovieLense) / (dim(MovieLense)[1] * dim(MovieLense)[2]) * 100
```

# Datenreduktion
## Aufgabe 2: Reduziere den MovieLense Datensatz auf rund 400 Kunden und 700 Filme, indem du Filme und Kunden mit sehr wenigen Ratings entfernst.

### DataFrame neu einlesen
```{r}
MovieLenseToCut <- as(MovieLense, "data.frame")
```

### Auswahl der 400 Kunden
```{r}
MovieLense400User <- MovieLenseToCut %>% 
  group_by(user) %>% 
  summarize(Anzahl = n()) %>% 
  arrange(desc(Anzahl)) %>% 
  slice(0:400)
head(MovieLense400User)
```

### Auswahl der 700 Movies
```{r}
MovieLense700Items <- MovieLenseToCut %>% 
  group_by(item) %>% 
  summarise(Anzahl = n()) %>% 
  arrange(desc(Anzahl)) %>% 
  slice(0:700)
head(MovieLense700Items)
```

### DataFrame schneiden
```{r}
MovieLenseCut <- MovieLenseToCut %>% 
  filter(user %in% c(MovieLense400User$user))

MovieLenseCut <- MovieLenseCut %>% 
  filter(item %in% c(MovieLense700Items$item))


```

Untersuche und dokumentiere die Eigenschaften des reduzierten Datensatzes und beschreibe den Effekt der Datenreduktion, d.h.

## 1. Anzahl Filme und Kunden sowie Sparsity vor und nach Datenreduktion,

### Vor der Datenreduktion
```{r}
image(MovieLense)
```

```{r}
nratings(MovieLense) / (dim(MovieLense)[1] * dim(MovieLense)[2]) * 100

```


### Nach Datenreduktion
```{r}
MovieLenseCompact <- as(MovieLenseCut, "realRatingMatrix")
image(MovieLenseCompact)
```

### Vergleich der Sparsity
```{r}
nratings(MovieLenseCompact) / (dim(MovieLenseCompact)[1] * dim(MovieLenseCompact)[2]) * 100

# Interpreation
```

##2. Mittlere Kundenratings pro Film vor und nach Datenreduktion,

```{r}
MovieLenseCut %>% 
  group_by(item) %>% 
  summarize(mean_rating_per_film = mean(rating)) %>% 
  ggplot(aes(x = mean_rating_per_film)) + 
  geom_histogram(color = "black", fill = "lightblue", binwidth = 0.5) +
    labs(x = "Ratings", 
       y = "Anzahl", 
       title = "Mittlere Kundenratings verteilung",
       subtitle = "MovieLenseData")
  
# Willst du eine Verteilung fuer jeden Film oder reicht dir eine Tabelle?

```

## 3. Für Gruppen: Quantifiziere “Intersection over Union” der Ratings der unterschiedlich reduzierten Datensätze.

```{r}
# Fragezeichen? 

```

# Analyse Ähnlichkeitsmatrix

## Aufgabe 3: Erzeuge einen IBCF Recommender und analysiere die Ähnlichkeitsmatrix des trainierten Modelles für den reduzierten Datensatz.

## 1. Zerlege den reduzierten MovieLense Datensatz in ein disjunktes Trainings-und Testdatenset im Verhältnis 4:1,

```{r}
training <- MovieLenseCompact[1:320] 
test <- MovieLenseCompact[321:400]

training
test
```

## 2. Trainiere ein IBCF Modell mit 30 Nachbarn und Cosine Similarity

```{r}
ribcf <- Recommender(training, "IBCF", param=list(k= 30, method = "cosine"))
ribcf
```

## 3. Bestimme die Verteilung der Filme, welche bei IBCF für paarweise Ähnlichkeitsvergleiche verwendet werden,

```{r}
names(getModel(ribcf))
```

```{r}
getModel(ribcf)$topN

# ??? 
```


##4. Bestimme die Filme, die am häufigsten in der Cosine-Ähnlichkeitsmatrix auftauchen und analysiere deren Vorkommen und Ratings im reduzierten Datensatz.

```{r}
#ribcftopNList <- as(ribcftopNList, "list")
#ribcftopNList <- combine(ribcftopNList)
#ribcftopNList <- data.frame(ribcftopNList)
#ribcftopNList <- ribcftopNList %>% group_by(ribcftopNList) %>% summarise(Anzahl = n()) %>% arrange(desc(Anzahl))
#ribcftopNList"""

#??? 
```




# Implementierung Ähnlichkeitsmatrix
Aufgabe 4 (DIY): Implementiere eine Funktion zur effizienten
Berechnung von sparsen Ähnlichkeitsmatrizen für IBCF RS und
analysiere die Resultate für 100 zufällig gewählte Filme.



## 1. Implementiere eine Funktion, um (a) für ordinale Ratings effizient
die Cosine Similarity und (b) für binäre Ratings effizient die Jaccard
Similarity zu berechnen,

```{r}
as(MovieLenseCompact, "data.frame")
DfforSimMatrix <- getRatingMatrix(MovieLenseCompact)
```


### Cosine Similarity 
```{r}
cosin_sim <- t(DfforSimMatrix) / sqrt(rowSums(t(DfforSimMatrix) * t(DfforSimMatrix)))
cosin_sim_mat <- cosin_sim %*% t(cosin_sim)
#cosin_sim_mat
```

### Jaccard Similarity
```{r}
# Noch zu kopieren aus Vorlage
```



## 2. Vergleiche deine Implementierung der Cosine-basierten
Ähnlichkeitsmatrix für ordinale Ratings mit der via recommenderlab
und einem anderen R-Paket erzeugten Ähnlichkeitsmatrix,

```{r}
library(lsa)

rec_simMat <- similarity(MovieLenseCompact[,1:3], which = "items")
rec_simMat

# simMat_lsa <- cosine(DfforSimMatrix, y = NULL)
```


Platzhalter für Rescaling der Matrizen
```{r}

```

##3. Vergleiche deine mittels Cosine Similarity erzeugten Ähnlichkeitsmatrix für ordinale Ratings mit der Jaccard-basierten
Ähnlichkeitsmatrix für binäre Ratings.

```{r}

```


# Analyse Top-N Listen - IBCF vs UBCF
Aufgabe 5: Vergleiche und diskutiere Top-N Empfehlungen von IBCF
und UBCF Modellen mit 30 Nachbarn und Cosine Similarity für den
reduzierten Datensatz.

## 1. Berechne Top-15 Empfehlungen für Testkunden mit IBCF und UBCF 

### ribcf & rubcf Modell trainieren
```{r}
ribcf <- Recommender(training, "IBCF", param=list(k= 30, method = "cosine"))
ribcf
rubcf <- Recommender(training, "UBCF", param=list(nn= 30, method = "cosine"))
rubcf
```
### Model Predicitions erstellen
```{r}
ribcftopNList = predict(ribcf, test, n=15)
ribcftopNList

rubcftopNList = predict(rubcf, test, n=15)
rubcftopNList
```

### 2. Vergleiche die Top-15 Empfehlungen und deren Verteilung und
diskutiere Gemeinsamkeiten und Unterschiede zwischen IBCF und
UBCF für alle Testkunden.

```{r}
cftopNList_to_df <- function(cftopNList, namedf){
  temp <- as(cftopNList, "list") %>% combine() %>% data.frame()
  colnames(temp)[1]  <- namedf
  temp <- temp %>%
    group_by_at(1) %>%
    summarise(Anzahl = n()) %>%
    arrange(desc(Anzahl))
  temp
}
```



```{r}
ribcftopNList <- cftopNList_to_df(ribcftopNList, "ribcftopNList")
ribcftopNList


rubcftopNList <- cftopNList_to_df(rubcftopNList, "rubcftopNList")
rubcftopNList
```

### Verteilungen visualisieren
```{r}
ribcftopNList %>% 
  ggplot(aes(x = Anzahl)) + 
  geom_histogram(fill = "lightblue", color = "black") +
  labs(title = "Verteilung der Anzahl Empfehlungen ribcf")
```



```{r}
rubcftopNList %>% 
  ggplot(aes(x = Anzahl)) + 
  geom_histogram(fill = "lightblue", color = "black") +
  labs(title = "Verteilung der Anzahl Empfehlungen rubcf")
```
Die erwähnte Behauptung “Recommender Systeme machen für alle Nutzer die gleichen Empfehlungen” kann dank dieser Histogramme verworfen werden. Sehr viele Filme werden nur wenigen User (<4) empfohlen.
Weiterer Text folgt.


# Analyse Top-N Listen - Ratings

Aufgabe 6: Untersuche den Einfluss von Ratings (ordinale vs binäre Ratings) und Modelltyp (IBCF vs UBCF) auf Top-N Empfehlungen für den reduzierten Datensatz. Vergleiche den Anteil übereinstimmender Empfehlungen der Top-15 Liste für

## 1. IBCF vs UBCF, beide mit ordinalem Rating und Cosine Similarity für alle Testkunden,

```{r}
paste("Anzahl IBCF:", nrow(ribcftopNList))
paste("Anzahl UBCF:", nrow(rubcftopNList))
IntersectordRatCosine <- intersect(ribcftopNList$ribcftopNList, rubcftopNList$rubcftopNList)
paste("Anzahl gemeinsame Empfehlungen:", length(IntersectordRatCosine))
paste("Anteil IBCF:", length(IntersectordRatCosine) / nrow(ribcftopNList) * 100)
paste("Anteil UBCF:", length(IntersectordRatCosine) / nrow(rubcftopNList) * 100)
```


## 2.IBCF vs UBCF, beide mit binärem Rating und Jaccard Similarity für alle Testkunden,

```{r}
training_bin <- binarize(training, minRating = 4)
test_bin <- binarize(test, minRating = 4)

ribcf_bin <- Recommender(training_bin, "IBCF", param=list(k= 30, method = "jaccard"))
ribcf_bin
rubcf_bin <- Recommender(training_bin, "UBCF", param=list(nn= 30, method = "jaccard"))
rubcf_bin
```

```{r}
ribcftopNList_bin = predict(ribcf_bin, test_bin, n=15)
ribcftopNList_bin
rubcftopNList_bin = predict(rubcf_bin, test_bin, n=15)
rubcftopNList_bin
```

```{r}
ribcftopNList_bin <- cftopNList_to_df(ribcftopNList_bin, "ribcftopNList_bin")
ribcftopNList_bin

rubcftopNList_bin <- cftopNList_to_df(rubcftopNList_bin, "rubcftopNList_bin")
rubcftopNList_bin
```

```{r}
paste("Anzahl IBCF binär:", nrow(ribcftopNList_bin))
paste("Anzahl UBCF binär:", nrow(rubcftopNList_bin))
IntersectbinRatJaccard <- intersect(ribcftopNList_bin$ribcftopNList_bin, rubcftopNList_bin$rubcftopNList_bin)
paste("Anzahl gemeinsame Empfehlungen binär:", length(IntersectbinRatJaccard))
paste("Anteil IBCF binär:", length(IntersectbinRatJaccard) / nrow(ribcftopNList_bin) * 100)
paste("Anteil UBCF binär:", length(IntersectbinRatJaccard) / nrow(rubcftopNList_bin) * 100)
```
Zu diskutieren: Wieso sind die Anzahl Übereinstimmungen am höchsten sind, wenn minRating 5 ist.


## 3.UBCF mit ordinalem (Cosine Similarity) vs UBCF mit binärem Rating (Jaccard Similarity) für alle Testkunden.

```{r}
paste("Anzahl UBCF:", nrow(rubcftopNList))
paste("Anzahl UBCF binär:", nrow(rubcftopNList_bin))
Intersectmixed <- intersect(rubcftopNList$rubcftopNList, rubcftopNList_bin$rubcftopNList_bin)
paste("Anzahl gemeinsame Empfehlungen gemischt:", length(Intersectmixed))
paste("Anzahl UBCF:", length(Intersectmixed) / nrow(rubcftopNList) * 100)
paste("Anteil UBCF binär:", length(Intersectmixed) / nrow(rubcftopNList_bin) * 100)
```

```{r}
#Histogramm der Vergleiche
```


# Analyse Top-N Listen -IBCF vs SVD

## Aufgabe 7: Vergleiche

Memory-based IBCF und Modell-based SVD Recommenders bezüglich Überschneidung ihrer Top-N Empfehlungen für die User-Item Matrix des reduzierten Datensatzes (Basis: reduzierter Datensatz, IBCF mit 30 Nachbarn und Cosine Similarity).

Vergleiche wie sich der Anteil übereinstimmender Empfehlungen der Top-15 Liste für IBCF vs verschiedene SVD Modelle verändert, wenn die Anzahl der Singulärwerte für SVD von 10 auf 20, 30, 40, 50 verändert wird.


```{r}
generate_SVD_topNList<- function(ksvd){
	temp <- Recommender(training, "SVD", param=list(k= ksvd))
	temp = predict(temp, test, n=15)
  temp
}
```


```{r}
rsvd10topNList <- generate_SVD_topNList(10)
rsvd20topNList <- generate_SVD_topNList(20)
rsvd30topNList <- generate_SVD_topNList(30)
rsvd40topNList <- generate_SVD_topNList(40)
rsvd50topNList <- generate_SVD_topNList(50)
```



```{r}
rsvd10topNList <- cftopNList_to_df(rsvd10topNList, "rsvd10topNList")
rsvd20topNList <- cftopNList_to_df(rsvd20topNList, "rsvd20topNList")
rsvd30topNList <- cftopNList_to_df(rsvd30topNList, "rsvd30topNList")
rsvd40topNList <- cftopNList_to_df(rsvd40topNList, "rsvd40topNList")
rsvd50topNList <- cftopNList_to_df(rsvd50topNList, "rsvd50topNList")
```



```{r}
IntersectIBCFSVD10 <- intersect(ribcftopNList$ribcftopNList, rsvd10topNList$rsvd10topNList)
paste("Anzahl gemeinsame Empfehlungen SVD10:", length(IntersectIBCFSVD10))
paste("Anteil SVD10:", length(IntersectIBCFSVD10) / nrow(rsvd10topNList) * 100)

IntersectIBCFSVD20 <- intersect(ribcftopNList$ribcftopNList, rsvd20topNList$rsvd20topNList)
paste("Anzahl gemeinsame Empfehlungen SVD20:", length(IntersectIBCFSVD20))
paste("Anteil SVD20:", length(IntersectIBCFSVD20) / nrow(rsvd20topNList) * 100)

IntersectIBCFSVD30 <- intersect(ribcftopNList$ribcftopNList, rsvd30topNList$rsvd30topNList)
paste("Anzahl gemeinsame Empfehlungen SVD30:", length(IntersectIBCFSVD30))
paste("Anteil SVD30:", length(IntersectIBCFSVD30) / nrow(rsvd30topNList) * 100)

IntersectIBCFSVD40 <- intersect(ribcftopNList$ribcftopNList, rsvd40topNList$rsvd40topNList)
paste("Anzahl gemeinsame Empfehlungen SVD40:", length(IntersectIBCFSVD40))
paste("Anteil SVD40:", length(IntersectIBCFSVD40) / nrow(rsvd40topNList) * 100)

IntersectIBCFSVD50 <- intersect(ribcftopNList$ribcftopNList, rsvd50topNList$rsvd50topNList)
paste("Anzahl gemeinsame Empfehlungen SVD50:", length(IntersectIBCFSVD50))
paste("Anteil SVD50:", length(IntersectIBCFSVD50) / nrow(rsvd50topNList) * 100)
```

# Implementierung Top-N Metriken

# Wahl des optimalen Recommenders

## Aufgabe 9

### 1. Verwende für die Evaluierung 10-fache Kreuzvalidierung
```{r}
set.seed(1234)
scheme <- evaluationScheme(MovieLenseCompact, method="cross-validation", k = 10, given=3, goodRating=5)
scheme
```


### 2. Begründe deine Wahl von Metriken und Modell

```{r}
algorithms <- list("hybrid" = list(name = "HYBRID", param =list(recommenders = list(SVD = list(name="SVD", param=list(k = 40)),
                                                                                    POPULAR = list(name = "POPULAR", param = NULL)
                                                                                    ))),
                   "libmf" = list(name="LIBMF", param=list(dim=10)),
                   "popular items" = list(name="POPULAR", param=NULL),
                   "user-based CF" = list(name="UBCF", param=list(nn=50)),
                   "item-based CF" = list(name="IBCF", param=list(k=50)),
                   "SVD40" = list(name="SVD", param=list(k = 40)))
results <- evaluate(scheme, algorithms, type = "topNList", n=c(10, 15, 20, 25, 30))
```

```{r}
plot(results, annotate=c(1,3), legend="topleft")
```

### 3. Analysiere das beste Modell für Top-N Recommendations mit N = 10, 15, 20, 25 und 30,
vieles blabaalabaaassss


### 4. Optimiere dein bestes Modell hinsichtlich Hyperparametern

```{r}
algorithmsimprovedrecom <- list("popular items center" = list(name="POPULAR", param=NULL),
                   "popular items Z-score" = list(name="POPULAR", param=list(normalize="Z-score")))
resultsimprovedrecom <- evaluate(scheme, algorithmsimprovedrecom, type = "topNList", n=c(10, 15, 20, 25, 30))
```

```{r}
plot(resultsimprovedrecom, annotate=c(1,3), legend="topleft")
```


Hinweis: Verwende für den Top-Movie Recommender die Filme mit den höchsten Durchschnittsratings.


# Implementierung Top-N Monitor
